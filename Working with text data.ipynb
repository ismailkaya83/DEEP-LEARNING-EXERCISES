{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colabdafordongusuuzunsurdu.ipynb",
      "provenance": [],
      "mount_file_id": "1PsZoegiEskqBfNhksklmBNJWlKug91sU",
      "authorship_tag": "ABX9TyO6XAzMXnKncfgEm8YQNrBf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ismailkaya83/MY-DEEP-LEARNING-NOTEBOOKS/blob/master/Working%20with%20text%20data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8eTyh1QOk0l"
      },
      "source": [
        "# **Working with text data**\n",
        "\n",
        "Like all other neural networks, deep-learning models don’t take as input raw text: they only work with numeric tensors. Vectorizing text is the process of transforming text into numeric tensors. This can be done in multiple ways:\n",
        "\n",
        "- Segment text into words, and transform each word into a vector.\n",
        "- Segment text into characters, and transform each character into a vector.\n",
        "- Extract n-grams of words or characters, and transform each n-gram into a vector. N-grams are overlapping groups of multiple consecutive words or characters.\n",
        "\n",
        "Collectively, the different units into which you can break down text (words, characters, or n-grams) are called **tokens**, and breaking text into such tokens is called **tokenization**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZykQXJ5ASHk5"
      },
      "source": [
        "## **One-hot encoding of words and characters**\n",
        "\n",
        "One-hot encoding is the most common, most basic way to turn a token into a vector. It consists of associating a unique integer index with every word and then turning this integer index i into a binary vector of size N (the size of the vocabulary); the vector is all zeros except for the ith entry, which is 1.\n",
        "\n",
        "Of course, one-hot encoding can be done at the character level, as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg3lXPWLSOpV"
      },
      "source": [
        "### **Word-level one-hot encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx1Q19HNO-2l"
      },
      "source": [
        "#Word-level one-hot encoding (toy example) kelime seviyesinde kodlama\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "\n",
        "token_index = {}\n",
        "\n",
        "for sample in samples:\n",
        "    for word in sample.split():\n",
        "        if word not in token_index:\n",
        "            token_index[word] = len(token_index) + 1"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwUCFoOEPNdg",
        "outputId": "40238f6b-3f16-46a1-f339-ede998131aa2"
      },
      "source": [
        "token_index"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'The': 1,\n",
              " 'ate': 8,\n",
              " 'cat': 2,\n",
              " 'dog': 7,\n",
              " 'homework.': 10,\n",
              " 'mat.': 6,\n",
              " 'my': 9,\n",
              " 'on': 4,\n",
              " 'sat': 3,\n",
              " 'the': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MypW4BguPPu5"
      },
      "source": [
        "max_length = 10 #her ornekte ilk 10 kelime dikkate alinacak\n",
        "\n",
        "results = np.zeros(shape=(len(samples),\n",
        "                          max_length, \n",
        "                          max(token_index.values()) +1)) # degerleri sakladiginiz yer"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LslWmt8oPSZa",
        "outputId": "513ba49d-aa46-4b27-cc96-dfd347d8c9ce"
      },
      "source": [
        "results.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 10, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90EiiQ2sPVTq"
      },
      "source": [
        "for i, sample in enumerate(samples):\n",
        "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
        "        index = token_index.get(word)\n",
        "        results[i, j, index] = 1."
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHrL3brJPX-f",
        "outputId": "12012716-734c-40f2-933e-634ffc23aa6a"
      },
      "source": [
        "for i, sample in enumerate(samples):\n",
        "    print(i, sample)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 The cat sat on the mat.\n",
            "1 The dog ate my homework.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdmiQ_sNPbJe",
        "outputId": "649a8bd2-5e97-46bf-a65d-011ab80ae964"
      },
      "source": [
        "list(enumerate(\"The cat sat on the mat.\".split()))[:max_length]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 'The'), (1, 'cat'), (2, 'sat'), (3, 'on'), (4, 'the'), (5, 'mat.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh66fBOuPem4"
      },
      "source": [
        "### **Character-level one-hot encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5dXd1l9Pf-w"
      },
      "source": [
        "# Character-level one-hot encoding (toy example) Karakter seviyesinde kodlama\n",
        "\n",
        "import string\n",
        "\n",
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "\n",
        "characters = string.printable # tum yazdirilabilir ASCII karakterler\n",
        "\n",
        "token_index = dict(zip(range(1, len(characters) + 1), characters))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ghHDGCDQPi6s",
        "outputId": "5eeff62c-780f-4726-e6d8-cd57e7a00aaf"
      },
      "source": [
        "characters"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqVBNHgDPk-O",
        "outputId": "afa06ad0-3226-4a57-b9e0-bfbdfd1441b0"
      },
      "source": [
        "token_index"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: '0',\n",
              " 2: '1',\n",
              " 3: '2',\n",
              " 4: '3',\n",
              " 5: '4',\n",
              " 6: '5',\n",
              " 7: '6',\n",
              " 8: '7',\n",
              " 9: '8',\n",
              " 10: '9',\n",
              " 11: 'a',\n",
              " 12: 'b',\n",
              " 13: 'c',\n",
              " 14: 'd',\n",
              " 15: 'e',\n",
              " 16: 'f',\n",
              " 17: 'g',\n",
              " 18: 'h',\n",
              " 19: 'i',\n",
              " 20: 'j',\n",
              " 21: 'k',\n",
              " 22: 'l',\n",
              " 23: 'm',\n",
              " 24: 'n',\n",
              " 25: 'o',\n",
              " 26: 'p',\n",
              " 27: 'q',\n",
              " 28: 'r',\n",
              " 29: 's',\n",
              " 30: 't',\n",
              " 31: 'u',\n",
              " 32: 'v',\n",
              " 33: 'w',\n",
              " 34: 'x',\n",
              " 35: 'y',\n",
              " 36: 'z',\n",
              " 37: 'A',\n",
              " 38: 'B',\n",
              " 39: 'C',\n",
              " 40: 'D',\n",
              " 41: 'E',\n",
              " 42: 'F',\n",
              " 43: 'G',\n",
              " 44: 'H',\n",
              " 45: 'I',\n",
              " 46: 'J',\n",
              " 47: 'K',\n",
              " 48: 'L',\n",
              " 49: 'M',\n",
              " 50: 'N',\n",
              " 51: 'O',\n",
              " 52: 'P',\n",
              " 53: 'Q',\n",
              " 54: 'R',\n",
              " 55: 'S',\n",
              " 56: 'T',\n",
              " 57: 'U',\n",
              " 58: 'V',\n",
              " 59: 'W',\n",
              " 60: 'X',\n",
              " 61: 'Y',\n",
              " 62: 'Z',\n",
              " 63: '!',\n",
              " 64: '\"',\n",
              " 65: '#',\n",
              " 66: '$',\n",
              " 67: '%',\n",
              " 68: '&',\n",
              " 69: \"'\",\n",
              " 70: '(',\n",
              " 71: ')',\n",
              " 72: '*',\n",
              " 73: '+',\n",
              " 74: ',',\n",
              " 75: '-',\n",
              " 76: '.',\n",
              " 77: '/',\n",
              " 78: ':',\n",
              " 79: ';',\n",
              " 80: '<',\n",
              " 81: '=',\n",
              " 82: '>',\n",
              " 83: '?',\n",
              " 84: '@',\n",
              " 85: '[',\n",
              " 86: '\\\\',\n",
              " 87: ']',\n",
              " 88: '^',\n",
              " 89: '_',\n",
              " 90: '`',\n",
              " 91: '{',\n",
              " 92: '|',\n",
              " 93: '}',\n",
              " 94: '~',\n",
              " 95: ' ',\n",
              " 96: '\\t',\n",
              " 97: '\\n',\n",
              " 98: '\\r',\n",
              " 99: '\\x0b',\n",
              " 100: '\\x0c'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XluLyUPJPoLY"
      },
      "source": [
        "max_length = 50\n",
        "\n",
        "results = np.zeros((len(samples), max_length, max(token_index.keys()) + 1))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vriVAYTPy7J",
        "outputId": "85cef06b-84ff-4eac-a446-1a6244ff208f"
      },
      "source": [
        "results.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 50, 101)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EsqS82yQGPO"
      },
      "source": [
        "for i, sample in enumerate(samples):\n",
        "    for j, character in enumerate(sample):\n",
        "        index = token_index.get(character)\n",
        "        results[i, j, index] =1."
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg6oTDENQIdd",
        "outputId": "93891a1f-67ed-4728-870f-9cc63d018be0"
      },
      "source": [
        "results"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gw0b5g2QL-i"
      },
      "source": [
        "### **Using Keras for word-level one-hot encoding**\n",
        "\n",
        "Note that Keras has built-in utilities for doing one-hot encoding of text at the word level or character level, starting from raw text data. You should use these utilities, because they take care of a number of important features such as stripping special characters from strings and only taking into account the N most common words in your dataset (a common restriction, to avoid dealing with very large input vector spaces)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHfRDDXPQPAL"
      },
      "source": [
        "# Using Keras for word-level one-hot encoding\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ85ztLKQRVR"
      },
      "source": [
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "\n",
        "tokenizer = Tokenizer(num_words=1000) # 1000 yaygin kelime icin andic ayirici"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orCOOphZQRbF"
      },
      "source": [
        "tokenizer.fit_on_texts(samples) # kelime indeksleri olusturur."
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU4avUqhQReE"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(samples) # metinleri tam sayi listelerine donusturur."
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhsnvxvDQRhW",
        "outputId": "298ba2c9-afd5-4bb1-d1fc-9bb675a92205"
      },
      "source": [
        "sequences"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "letzwzs5QRkM"
      },
      "source": [
        "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghAIzO3xQacw",
        "outputId": "09d4a970-3470-4198-963b-82eb6e437092"
      },
      "source": [
        "one_hot_results"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJlHsJvxQafg"
      },
      "source": [
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y48a_8HAQaiH",
        "outputId": "774466d4-3225-4eb1-81bc-7aa5d3d7f919"
      },
      "source": [
        "word_index"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ate': 7,\n",
              " 'cat': 2,\n",
              " 'dog': 6,\n",
              " 'homework': 9,\n",
              " 'mat': 5,\n",
              " 'my': 8,\n",
              " 'on': 4,\n",
              " 'sat': 3,\n",
              " 'the': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKrkXWqPQamc",
        "outputId": "f91898bd-e024-4e8b-c54b-519d624c1fd0"
      },
      "source": [
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXss5pb4Qh84"
      },
      "source": [
        "### **Word-level one-hot encoding with hashing trick**\n",
        "\n",
        "A variant of one-hot encoding is the so-called one-hot hashing trick, which you can use when the number of unique tokens in your vocabulary is too large to handle explicitly. Instead of explicitly assigning an index to each word and keeping a reference of these indices in a dictionary, you can hash words into vectors of fixed size. This is typically done with a very lightweight hashing function. The main advantage of this method is that it does away with maintaining an explicit word index, which saves memory and allows online encoding of the data (you can generate token vectors right away, before you’ve seen all of the available data). The one drawback of this approach is that it’s susceptible to hash collisions: two different words may end up with the same hash, and subsequently any machine-learning model looking at these hashes won’t be able to tell the difference between these words. The likelihood of hash collisions decreases when the dimensionality of the hashing space is much larger than the total number of unique tokens being hashed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3Ni6gD0QapR"
      },
      "source": [
        "#hash kodlama hilesi\n",
        "\n",
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "\n",
        "dimensionality = 1000\n",
        "#1000 kelimelik vektorler saklar. Eger 1000 den fazla veya yakin sayida kelimeniz varsa hash kodlama hatasi alabilirsiniz\n",
        "\n",
        "max_length = 10\n",
        "\n",
        "results = np.zeros((len(samples), max_length, dimensionality))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s0NMCRZQpnE"
      },
      "source": [
        "for i, sample in enumerate(samples):\n",
        "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
        "        index=abs(hash(word)) % dimensionality # kelimeyi 0 ile 1000 arasindaki rastgele bir tamsayiya hash kodlar\n",
        "        \n",
        "        results[i, j, index] = 1."
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu842RkgQpp1",
        "outputId": "441d1336-9f00-4e26-94ef-7151bbc451be"
      },
      "source": [
        "results"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBNkxjVQ1_g"
      },
      "source": [
        "## **Using word embeddings**\n",
        "\n",
        "Another popular and powerful way to associate a vector with a word is the use of dense word vectors, also called word embeddings. Whereas the vectors obtained through one-hot encoding are binary, sparse (mostly made of zeros), and very high-dimensional (same dimensionality as the number of words in the vocabulary), word embeddings are low-dimensional floating-point vectors (that is, dense vectors, as opposed to sparse vectors); see figure 6.2. Unlike the word vectors obtained via one-hot encoding, word embeddings are learned from data. It’s common to see word embeddings that are 256-dimensional, 512-dimensional, or 1,024-dimensional when dealing with very large vocabularies. On the other hand, one-hot encoding words generally leads to vectors that are 20,000-dimensional or greater (capturing a vocabulary of 20,000 tokens, in this case). So, word embeddings pack more information into far fewer dimensions.\n",
        "\n",
        "There are two ways to obtain word embeddings:\n",
        "\n",
        "- Learn word embeddings jointly with the main task you care about (such as document classification or sentiment prediction). In this setup, you start with random word vectors and then learn word vectors in the same way you learn the weights of a neural network.\n",
        "- Load into your model word embeddings that were precomputed using a different machine-learning task than the one you’re trying to solve. These are called pretrained word embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyvJFU1XTeEx"
      },
      "source": [
        "### **Learning word embeddings with the Embedding layer**\n",
        "\n",
        "this approach is that the resulting embedding space has no structure: for instance, the words accurate and exact may end up with completely different embeddings, even though they’re interchangeable in most sentences. It’s difficult for a deep neural network to make sense of such a noisy, unstructured embedding space.\n",
        "\n",
        "To get a bit more abstract, the geometric relationships between word vectors should reflect the semantic relationships between these words. Word embeddings are meant to map human language into a geometric space. For instance, in a reasonable embedding space, you would expect synonyms to be embedded into similar word vectors; and in general, you would expect the geometric distance (such as L2 distance) between any two word vectors to relate to the semantic distance between the associated words (words meaning different things are embedded at points far away from each other, whereas related words are closer). In addition to distance, you may want specific directions in the embedding space to be meaningful. To make this clearer, let’s look at a concrete example.\n",
        "\n",
        "In figure 6.3, four words are embedded on a 2D plane: cat, dog, wolf, and tiger. With the vector representations we chose here, some semantic relationships between these words can be encoded as geometric transformations. For instance, the same vector allows us to go from cat to tiger and from dog to wolf: this vector could be interpreted as the “from pet to wild animal” vector. Similarly, another vector lets us go from dog to cat and from wolf to tiger, which could be interpreted as a “from canine to feline” vector.\n",
        "\n",
        "In real-world word-embedding spaces, common examples of meaningful geometric transformations are “gender” vectors and “plural” vectors. For instance, by adding a “female” vector to the vector “king,” we obtain the vector “queen.” By adding a “plural” vector, we obtain “kings.” Word-embedding spaces typically feature thousands of such interpretable and potentially useful vectors.\n",
        "\n",
        "Is there some ideal word-embedding space that would perfectly map human language and could be used for any natural-language-processing task? Possibly, but we have yet to compute anything of the sort. Also, there is no such a thing as human language—there are many different languages, and they aren’t isomorphic, because a language is the reflection of a specific culture and a specific context. But more pragmatically, what makes a good word-embedding space depends heavily on your task: the perfect word-embedding space for an English-language movie-review sentiment-analysis model may look different from the perfect embedding space for an English-language legal--document-classification model, because the importance of certain semantic relationships varies from task to task.\n",
        "\n",
        "It’s thus reasonable to learn a new embedding space with every new task. Fortunately, backpropagation makes this easy, and Keras makes it even easier. It’s about learning the weights of a layer: the Embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmMkGeC5RFZS"
      },
      "source": [
        "# Instantiating an Embedding layer (embaddin katmani olusturmak)\n",
        "\n",
        "from keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(1000, 64) \n",
        "#embedding katmani en azindan iki parametre alir: Maksimum andic sayisi ve gomulmenin boyutu"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G5NuzKmRJ-F"
      },
      "source": [
        "The Embedding layer is best understood as a dictionary that maps integer indices (which stand for specific words) to dense vectors. It takes integers as input, it looks up these integers in an internal dictionary, and it returns the associated vectors.\n",
        "\n",
        "The Embedding layer takes as input a 2D tensor of integers, of shape (samples, sequence_length), where each entry is a sequence of integers. It can embed sequences of variable lengths: for instance, you could feed into the Embedding layer in the previous example batches with shapes (32, 10) (batch of 32 sequences of length 10) or (64, 15) (batch of 64 sequences of length 15). All sequences in a batch must have the same length, though (because you need to pack them into a single tensor), so sequences that are shorter than others should be padded with zeros, and sequences that are longer should be truncated.\n",
        "\n",
        "This layer returns a 3D floating-point tensor of shape (samples, sequence_length, embedding_dimensionality). Such a 3D tensor can then be processed by an RNN layer or a 1D convolution layer (both will be introduced in the following sections).\n",
        "\n",
        "When you instantiate an Embedding layer, its weights (its internal dictionary of token vectors) are initially random, just as with any other layer. During training, these word vectors are gradually adjusted via backpropagation, structuring the space into something the downstream model can exploit. Once fully trained, the embedding space will show a lot of structure—a kind of structure specialized for the specific problem for which you’re training your model.\n",
        "\n",
        "Let’s apply this idea to the IMDB movie-review sentiment-prediction task that you’re already familiar with. First, you’ll quickly prepare the data. You’ll restrict the movie reviews to the top 10,000 most common words (as you did the first time you worked with this dataset) and cut off the reviews after only 20 words. The network will learn 8-dimensional embeddings for each of the 10,000 words, turn the input integer sequences (2D integer tensor) into embedded sequences (3D float tensor), flatten the tensor to 2D, and train a single Dense layer on top for classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-JsngAaRKZc"
      },
      "source": [
        "#Loading the IMDB data for use with an Embedding layer\n",
        "\n",
        "from keras.datasets import imdb\n",
        "from keras import preprocessing\n",
        "\n",
        "max_features = 10000 #toplam yegane kelime -sozluk buyuklugu- sayisi\n",
        "max_len = 20 #yorumdan alinacak kelime sayisi\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features) #veriyi tam sayi listesi olarak yukler"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbYoxBcIQpsX",
        "outputId": "fd50f7a0-5778-4dbd-eabd-c288ec3e0ca4"
      },
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000,), (25000,), (25000,), (25000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Woi2y4YTQpxw"
      },
      "source": [
        "# tam sayi listesini 2B tam sayi tensorune donusturur.\n",
        "\n",
        "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=max_len)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYmn2ZvJW-CJ",
        "outputId": "bd9d7f7d-b148-4076-b9ae-d7f38b4d9010"
      },
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000, 20), (25000,), (25000, 20), (25000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb0pasJOQpwQ",
        "outputId": "f2ad18e3-b591-444c-8199-fc41dea1fec9"
      },
      "source": [
        "# Using an Embedding layer and classifier on the IMDB data\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Embedding\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(10000, 8, input_length=max_len))\n",
        "# embedding katmaninin maksimum girdi uzunlugunu belirler. Boylece daha sonra gomulmeleri duzlestirebiliriz.\n",
        "# embedding katmanindan sonra aktivasyonlarin sekli (samples, maxlen, 8)\n",
        "\n",
        "model.add(Flatten()) # 3B gomulmeleri 2B tensor sekline getirir. (samples, maxlen*8)\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(x_train, y_train, \n",
        "                    epochs=10, \n",
        "                    batch_size=32, \n",
        "                    validation_split=0.2)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, 20, 8)             80000     \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 161       \n",
            "=================================================================\n",
            "Total params: 80,161\n",
            "Trainable params: 80,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6625 - acc: 0.6321 - val_loss: 0.6054 - val_acc: 0.7078\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5335 - acc: 0.7521 - val_loss: 0.5202 - val_acc: 0.7378\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4600 - acc: 0.7883 - val_loss: 0.4990 - val_acc: 0.7474\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4218 - acc: 0.8097 - val_loss: 0.4949 - val_acc: 0.7494\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3939 - acc: 0.8238 - val_loss: 0.4959 - val_acc: 0.7484\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3707 - acc: 0.8392 - val_loss: 0.4990 - val_acc: 0.7520\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3498 - acc: 0.8486 - val_loss: 0.5044 - val_acc: 0.7504\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3306 - acc: 0.8604 - val_loss: 0.5120 - val_acc: 0.7534\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3128 - acc: 0.8689 - val_loss: 0.5199 - val_acc: 0.7514\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.2964 - acc: 0.8773 - val_loss: 0.5278 - val_acc: 0.7482\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMai5gURRpu9"
      },
      "source": [
        "You get to a validation accuracy of ~74%, which is pretty good considering that you’re only looking at the first 20 words in every review. But note that merely flattening the embedded sequences and training a single Dense layer on top leads to a model that treats each word in the input sequence separately, without considering inter-word relationships and sentence structure (for example, this model would likely treat both “this movie is a bomb” and “this movie is the bomb” as being negative reviews). It’s much better to add recurrent layers or 1D convolutional layers on top of the embedded sequences to learn features that take into account each sequence as a whole."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE4NN6-HRqTF"
      },
      "source": [
        "### **Using pretrained word embeddings**\n",
        "\n",
        "Sometimes, you have so little training data available that you can’t use your data alone to learn an appropriate task-specific embedding of your vocabulary. What do you do then?\n",
        "\n",
        "Instead of learning word embeddings jointly with the problem you want to solve, you can load embedding vectors from a precomputed embedding space that you know is highly structured and exhibits useful properties—that captures generic aspects of language structure. The rationale behind using pretrained word embeddings in natural-language processing is much the same as for using pretrained convnets in image classification: you don’t have enough data available to learn truly powerful features on your own, but you expect the features that you need to be fairly generic—that is, common visual features or semantic features. In this case, it makes sense to reuse features learned on a different problem.\n",
        "\n",
        "Such word embeddings are generally computed using word-occurrence statistics (observations about what words co-occur in sentences or documents), using a variety of techniques, some involving neural networks, others not. The idea of a dense, low-dimensional embedding space for words, computed in an unsupervised way, was initially explored by Bengio et al. in the early 2000s,[1] but it only started to take off in research and industry applications after the release of one of the most famous and successful word-embedding schemes: the Word2vec algorithm (https://code.google.com/archive/p/word2vec), developed by Tomas Mikolov at Google in 2013. Word2vec dimensions capture specific semantic properties, such as gender.\n",
        "\n",
        "1Yoshua Bengio et al., Neural Probabilistic Language Models (Springer, 2003).\n",
        "\n",
        "There are various precomputed databases of word embeddings that you can download and use in a Keras Embedding layer. Word2vec is one of them. Another popular one is called Global Vectors for Word Representation (GloVe, https://nlp.stanford.edu/projects/glove), which was developed by Stanford researchers in 2014. This embedding technique is based on factorizing a matrix of word co-occurrence statistics. Its developers have made available precomputed embeddings for millions of English tokens, obtained from Wikipedia data and Common Crawl data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7TV5a54Rv2P"
      },
      "source": [
        "## **Putting it all together: from raw text to word embeddings**\n",
        "\n",
        "You’ll use a model similar to the one we just went over: embedding sentences in sequences of vectors, flattening them, and training a Dense layer on top. But you’ll do so using pretrained word embeddings; and instead of using the pretokenized IMDB data packaged in Keras, you’ll start from scratch by downloading the original text data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWQEh0rmT1hG"
      },
      "source": [
        "### **Downloading the IMDB data as raw text**\n",
        "\n",
        "First, head to http://mng.bz/0tIo and download the raw IMDB dataset. Uncompress it.\n",
        "\n",
        "Now, let’s collect the individual training reviews into a list of strings, one string per review. You’ll also collect the review labels (positive/negative) into a labels list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMvXZSwbX1JH"
      },
      "source": [
        "import os\n",
        "\n",
        "imdb_dir = '/content/drive/MyDrive/Colab_Notebooks/Deep_learning_for_text/aclImdb'\n",
        "train_dir = os.path.join(imdb_dir, 'train')\n",
        "\n",
        "labels = []\n",
        "texts = []\n",
        "\n",
        "for label_type in ['neg', 'pos']:\n",
        "    dir_name = os.path.join(train_dir, label_type)\n",
        "    for fname in os.listdir(dir_name):\n",
        "        if fname[-4:] == '.txt':\n",
        "            f = open(os.path.join(dir_name, fname))\n",
        "            texts.append(f.read())\n",
        "            f.close()\n",
        "            if label_type == 'neg':\n",
        "                labels.append(0)\n",
        "            else:\n",
        "                labels.append(1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aU7QT9IaZFw",
        "outputId": "a38303fc-31d1-42af-ecfe-2bab17f4bc28"
      },
      "source": [
        "len(labels), len(texts)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b6vTmUkX1g_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "e258bfd5-71b6-4003-d227-d075c6932668"
      },
      "source": [
        "texts[1]"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"This is an example of why the majority of action films are the same. Generic and boring, there's really nothing worth watching here. A complete waste of the then barely-tapped talents of Ice-T and Ice Cube, who've each proven many times over that they are capable of acting, and acting well. Don't bother with this one, go see New Jack City, Ricochet or watch New York Undercover for Ice-T, or Boyz n the Hood, Higher Learning or Friday for Ice Cube and see the real deal. Ice-T's horribly cliched dialogue alone makes this film grate at the teeth, and I'm still wondering what the heck Bill Paxton was doing in this film? And why the heck does he always play the exact same character? From Aliens onward, every film I've seen with Bill Paxton has him playing the exact same irritating character, and at least in Aliens his character died, which made it somewhat gratifying...<br /><br />Overall, this is second-rate action trash. There are countless better films to see, and if you really want to see this one, watch Judgement Night, which is practically a carbon copy but has better acting and a better script. The only thing that made this at all worth watching was a decent hand on the camera - the cinematography was almost refreshing, which comes close to making up for the horrible film itself - but not quite. 4/10.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unx-jrpVaftA",
        "outputId": "d4ce6045-d019-4355-a460-dbe62c5ecf2c"
      },
      "source": [
        "labels[1]"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDc9cZglaoqb"
      },
      "source": [
        "### **Tokenizing the data** (veriyi andiclara ayirmak)\n",
        "\n",
        "Let’s vectorize the text and prepare a training and validation split, using the concepts introduced earlier in this section. Because pretrained word embeddings are meant to be particularly useful on problems where little training data is available (otherwise, task-specific embeddings are likely to outperform them), we’ll add the following twist: restricting the training data to the first 200 samples. So you’ll learn to classify movie reviews after looking at just 200 examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnRe0TkebAaq",
        "outputId": "bfd2480a-e153-44ac-8683-7f19c6546d96"
      },
      "source": [
        "len(sequences)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuqkcSz2bc0H",
        "outputId": "f0a914ae-9ace-4113-b120-7ec081dbeb8a"
      },
      "source": [
        "len(sequences[1])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr46DcO-bxuj",
        "outputId": "a4219749-0dae-469b-ed11-2c170f207900"
      },
      "source": [
        "pad_sequences"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function tensorflow.python.keras.preprocessing.sequence.pad_sequences>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGO8y4oWcaoC",
        "outputId": "0fdd57ad-ebbe-45be-9344-bda9d4be89f7"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZeNbF-kX1RQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a784eb-0f60-4819-cf83-606b3d4cb0a5"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "maxlen = 100\n",
        "training_samples = 200\n",
        "validation_samples = 10000\n",
        "max_words = 10000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "labels = np.asarray(labels)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "x_train = data[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "x_val = data[training_samples: training_samples + validation_samples]\n",
        "y_val = labels[training_samples: training_samples + validation_samples]"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 88582 unique tokens.\n",
            "Shape of data tensor: (25000, 100)\n",
            "Shape of label tensor: (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSHIp9osdRpa"
      },
      "source": [
        "### **Downloading the GloVe word embeddings**\n",
        "\n",
        "Go to https://nlp.stanford.edu/projects/glove, and download the precomputed embeddings from 2014 English Wikipedia. It’s an 822 MB zip file called glove.6B.zip, containing 100-dimensional embedding vectors for 400,000 words (or nonword tokens). Unzip it.\n",
        "\n",
        "**Preprocessing the embeddings**\n",
        "\n",
        "Let’s parse the unzipped file (a .txt file) to build an index that maps words (as strings) to their vector representation (as number vectors)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBSzY6LnZJKx",
        "outputId": "aa4e854a-dcf0-4f67-f0a3-7f1f3f671a82"
      },
      "source": [
        "glove_dir = '/content/drive/MyDrive/Colab_Notebooks/Deep_learning_for_text/glove.6B'\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "000czRLhdbHa"
      },
      "source": [
        "Next, you’ll build an embedding matrix that you can load into an Embedding layer. It must be a matrix of shape (max_words, embedding_dim), where each entry i contains the embedding_dim-dimensional vector for the word of index i in the reference word index (built during tokenization). Note that index 0 isn’t supposed to stand for any word or token—it’s a placeholder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yFJybPnZZOw"
      },
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i < max_words:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db9PrjUpeLNK",
        "outputId": "7495e6e5-2e86-44da-8bca-749be6acd7cd"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNaFsAYtedGI",
        "outputId": "5db11c76-088d-46a1-849c-606b5a1dd47f"
      },
      "source": [
        "embedding_vector.shape"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkJKZygiZbEU",
        "outputId": "6f461f4c-ad12-43b1-c7c3-a613900e98d0"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 32)                320032    \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,320,065\n",
            "Trainable params: 1,320,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvsNc994lDSp"
      },
      "source": [
        "### **Loading the GloVe embeddings in the model**\n",
        "\n",
        "The Embedding layer has a single weight matrix: a 2D float matrix where each entry i is the word vector meant to be associated with index i. Simple enough. Load the GloVe matrix you prepared into the Embedding layer, the first layer in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9C1NyYSZtj_"
      },
      "source": [
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_6CYk70lRq0"
      },
      "source": [
        "Additionally, you’ll freeze the Embedding layer (set its trainable attribute to False), following the same rationale you’re already familiar with in the context of pretrained convnet features: when parts of a model are pretrained (like your Embedding layer) and parts are randomly initialized (like your classifier), the pretrained parts shouldn’t be updated during training, to avoid forgetting what they already know. The large gradient updates triggered by the randomly initialized layers would be disruptive to the already-learned features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KgiaA5wZyR5",
        "outputId": "a923f037-98b6-49cf-95b5-38f0fdadb0a3"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(x_val, y_val))\n",
        "model.save_weights('pre_trained_glove_model.h5')"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0824 - acc: 0.9934 - val_loss: 2.8052 - val_acc: 0.5002\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0182 - acc: 0.9962 - val_loss: 2.7322 - val_acc: 0.4982\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0241 - acc: 0.9937 - val_loss: 2.7588 - val_acc: 0.4969\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0273 - acc: 0.9941 - val_loss: 2.5493 - val_acc: 0.4959\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 7.5962e-04 - acc: 0.9997 - val_loss: 3.0465 - val_acc: 0.4980\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0254 - acc: 0.9944 - val_loss: 2.8237 - val_acc: 0.4992\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0244 - acc: 0.9941 - val_loss: 3.0272 - val_acc: 0.4946\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0146 - acc: 0.9959 - val_loss: 2.7151 - val_acc: 0.4971\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 7.3838e-04 - acc: 0.9994 - val_loss: 3.0076 - val_acc: 0.4982\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0116 - acc: 0.9937 - val_loss: 2.9068 - val_acc: 0.4978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "I-3KIFoWaNZT",
        "outputId": "8031678b-35b7-45b6-b947-5f3315b38f6a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LMmq15qmGTa"
      },
      "source": [
        "The model quickly starts overfitting, which is unsurprising given the small number of training samples. Validation accuracy has high variance for the same reason, but it seems to reach the high %50.\n",
        "\n",
        "Note that your mileage may vary: because you have so few training samples, performance is heavily dependent on exactly which 200 samples you choose—and you’re choosing them at random. If this works poorly for you, try choosing a different random set of 200 samples, for the sake of the exercise (in real life, you don’t get to choose your training data).\n",
        "\n",
        "You can also train the same model without loading the pretrained word embeddings and without freezing the embedding layer. In that case, you’ll learn a task--specific embedding of the input tokens, which is generally more powerful than pretrained word embeddings when lots of data is available. But in this case, you have only 200 training samples. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQo5RF4nadNC",
        "outputId": "aaa0190b-ad15-4be0-eef6-145a29928c6c"
      },
      "source": [
        "#Training the same model without pretrained word embeddings\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 32)                320032    \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,320,065\n",
            "Trainable params: 1,320,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6948 - acc: 0.4869 - val_loss: 0.6938 - val_acc: 0.4932\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.4614 - acc: 0.8963 - val_loss: 0.7648 - val_acc: 0.4923\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0804 - acc: 0.9937 - val_loss: 0.9527 - val_acc: 0.4960\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0062 - acc: 0.9997 - val_loss: 1.1674 - val_acc: 0.4941\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0039 - acc: 0.9997 - val_loss: 1.3695 - val_acc: 0.4931\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0032 - acc: 0.9997 - val_loss: 1.5228 - val_acc: 0.4945\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0011 - acc: 0.9994 - val_loss: 1.6387 - val_acc: 0.4966\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 4.3405e-04 - acc: 0.9997 - val_loss: 1.7056 - val_acc: 0.4960\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 4.3376e-04 - acc: 0.9997 - val_loss: 1.8143 - val_acc: 0.4956\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 4.3378e-04 - acc: 0.9997 - val_loss: 1.8978 - val_acc: 0.4952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "SRRdqFr2bnBt",
        "outputId": "d071c938-7ac7-44b6-d328-4617f41136ed"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm9gbEnGm6zz"
      },
      "source": [
        "Validation accuracy stalls in the low 50s. So in this case, pretrained word embeddings outperform jointly learned embeddings. If you increase the number of training samples, this will quickly stop being the case—try it as an exercise.\n",
        "\n",
        "Finally, let’s evaluate the model on the test data. First, you need to tokenize the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5XhlucVm8nB"
      },
      "source": [
        "test_dir = '/content/drive/MyDrive/Colab_Notebooks/Deep_learning_for_text/aclImdb/test'\n",
        "\n",
        "labels = []\n",
        "texts = []\n",
        "\n",
        "for label_type in ['neg', 'pos']:\n",
        "    dir_name = os.path.join(test_dir, label_type)\n",
        "    for fname in sorted(os.listdir(dir_name)):\n",
        "        if fname[-4:] == '.txt':\n",
        "            f = open(os.path.join(dir_name, fname))\n",
        "            texts.append(f.read())\n",
        "            f.close()\n",
        "            if label_type == 'neg':\n",
        "                labels.append(0)\n",
        "            else:\n",
        "                labels.append(1)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "x_test = pad_sequences(sequences, maxlen=maxlen)\n",
        "y_test = np.asarray(labels)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGDAJYTPPnPp",
        "outputId": "50e7aee2-3934-4012-b370-06c80a160912"
      },
      "source": [
        "model.load_weights('/content/pre_trained_glove_model.h5')\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 2s 2ms/step - loss: 2.8746 - acc: 0.4956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.874631643295288, 0.49559998512268066]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    }
  ]
}